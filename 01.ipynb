{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping a web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites are very often used to trick users into giving out information to malicious actors, or spread malware, or leak private information to third parties without the user's knowledge.\n",
    "\n",
    "Any website, especially when hosted somewhere, will give us information about the people behind it and how they operate. These information can be used to track a specific campaign, figure out the malicious actor(s) behind it, inform other potential targets of the attack, get a victim to act and avoid further consequences, or get in touch with the impersonated organisation so they take appropriate measures.\n",
    "\n",
    "It is also more and more comon to see nasty information leaks because of 3rd party components, or because a developper did a mistake. The problem is that with websites becoming more and more conplex, and many moving parts interacting together, investigating a website gets tricky very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "\n",
    "## The work environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following tutorial, we assume you have the following environment at your disposal.\n",
    "\n",
    "1. Ubuntu 20.04 or 21.10. It can be an other similar general purpose operating system (Debian 10, Fedora), but specialized distros such as Kali Linux are strongly discouraged and won't be supported if you have issues.\n",
    "\n",
    "   **Important note**: It is assumed that you're *not* running as root, but the account you're using is administrator (tl;dr: `sudo` works)\n",
    "\n",
    "2. Python 3.8 or 3.9.\n",
    "\n",
    "3. Basic command line tools: `curl`, `wget`, `grep`, `git`\n",
    "\n",
    "4. Poetry 1.1.0 (or more recent), preferably installed this way: \n",
    "\n",
    "  ```bash\n",
    "  curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py > get-poetry.py\n",
    "  python3 ./get-poetry.py\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry self -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone the repository (requires `git`)\n",
    "  ```bash\n",
    "  git clone https://github.com/Lookyloo/scraping-tutorial.git\n",
    "  cd scraping-tutorial\n",
    "  ```\n",
    "2. Install the dependencies:\n",
    "  ```bash\n",
    "  poetry install\n",
    "  ```\n",
    "3. Run the lab:\n",
    "  ```bash\n",
    "  poetry shell\n",
    "  jupyter-lab\n",
    "  ```\n",
    "4. Move to your browser. Running `jupyter-lab` should have opened a tab in your favorite browser. If it didn't, look in the terminal for hints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you're all setup for the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter will allow you to run commands the same way you would do that in a terminal, but also run python code, directly in your browser.\n",
    "\n",
    "All the code snipets can be executed by doing SHIFT + Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_world():\n",
    "    print(\">>>>> hello world\")\n",
    "    \n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a system command, you need to prepend it with `!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: The trivial approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, we will look at existing tools and use simple techniques to extract indicators from websites.\n",
    "\n",
    "**Goal**: get a listing of all the URLs a webpage loads content from. The content can be internal (same domain) or external (to a completely other domain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://circl.lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Commonly loaded stuff:\n",
    "\n",
    "* css stylesheets\n",
    "* fonts\n",
    "* icon\n",
    "* images\n",
    "\n",
    "Example of search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://circl.lu | grep raleway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "**Question**:\n",
    "* Do we see external content?\n",
    "* Can one of the stuff loaded by the page load something?\n",
    "\n",
    "\n",
    "Let's cheat and open that page in a browser and look at the network traffic:\n",
    "\n",
    "1. Open a new window in your favorite browser\n",
    "2. Go to `http://circl.lu`\n",
    "3. Open the dev tools\n",
    "  * Firefox: Right click > `Inspect Elements`\n",
    "  * Chrome/Chromium: Right click > `Inspect`\n",
    "4. Go to the `Network` tab\n",
    "5. Reload the page (F5)\n",
    "\n",
    "**Question**:\n",
    "\n",
    "* Why is this URL loaded ?! http://circl.lu/assets/fonts/raleway-regular.ttf\n",
    "\n",
    "Note: In Chrome/Chromium, the `Initiator` tab will tell you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not so simple Website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl salon.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wat?\n",
    "\n",
    "Let's figure out why that didn't return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -vvv salon.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a redirect (HTTP code 301).\n",
    "\n",
    "How do we follow that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!man curl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "       -L, --location\n",
    "              (HTTP) If the server reports that the requested page has moved to a different location (indicated with a Location: header and a 3XX response code),  this  option\n",
    "              will make curl redo the request on the new place. If used together with -i, --include or -I, --head, headers from all requested pages will be shown. When authen‐\n",
    "              tication is used, curl only sends its credentials to the initial host. If a redirect takes curl to a different host, it won't be able to intercept the user+pass‐\n",
    "              word. See also --location-trusted on how to change this. You can limit the amount of redirects to follow by using the --max-redirs option.\n",
    "\n",
    "              When  curl  follows a redirect and the request is not a plain GET (for example POST or PUT), it will do the following request with a GET if the HTTP response was\n",
    "              301, 302, or 303. If the response code was any other 3xx code, curl will re-send the following request using the same unmodified method.\n",
    "\n",
    "              You can tell curl to not change the non-GET request method to GET after a 30x response by  using  the  dedicated  options  for  that:  --post301,  --post302  and\n",
    "              --post303.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L salon.com | grep href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same as on the simple website above and search for internal and external resources loaded on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing website\n",
    "\n",
    "In order to find a valid and working phishing website, have a look at Phishtank:\n",
    "http://phishtank.org/phish_search.php?valid=y&active=y&Search=Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -vvv https://www.inelle.fr/modules/paypal/smarty/plugins/www.netflix.de/www/spotify/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -vvv  https://luxembourg-post.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
